# train_stop.py ‚Äî –û–ë–£–ß–ï–ù–ò–ï –ù–ê 150 –§–ê–ô–õ–ê–•
import os
import numpy as np
import librosa
import tensorflow as tf
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

DATA_DIR = "train_stop"
SR = 16000
N_MFCC = 13
MAX_LEN = 40

print("="*60)
print("   üß† –û–ë–£–ß–ï–ù–ò–ï –ù–ï–ô–†–û–°–ï–¢–ò –ù–ê 150 –§–ê–ô–õ–ê–•")
print("="*60)

def extract_mfcc(path):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ MFCC –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    try:
        audio, sr = librosa.load(path, sr=SR)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
        audio = audio / (np.max(np.abs(audio)) + 1e-6)
        
        # MFCC —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        mfcc = librosa.feature.mfcc(
            y=audio,
            sr=sr,
            n_mfcc=N_MFCC,
            n_fft=512,
            hop_length=256,
            n_mels=40
        )
        
        # –î–µ–ª—å—Ç–∞ –∏ –¥–µ–ª—å—Ç–∞-–¥–µ–ª—å—Ç–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã (—É–ª—É—á—à–∞—é—Ç —Ç–æ—á–Ω–æ—Å—Ç—å)
        mfcc_delta = librosa.feature.delta(mfcc)
        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        all_features = np.vstack([mfcc, mfcc_delta, mfcc_delta2])
        all_features = all_features.T  # (–∫–∞–¥—Ä—ã, 39 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
        
        # –û–±—Ä–µ–∑–∞–µ–º/–¥–æ–ø–æ–ª–Ω—è–µ–º
        if all_features.shape[0] < MAX_LEN:
            pad = np.zeros((MAX_LEN - all_features.shape[0], 39))
            all_features = np.vstack([all_features, pad])
        else:
            all_features = all_features[:MAX_LEN]
            
        return all_features
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {path}: {e}")
        return None

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
X = []
y = []

print("üì¶ –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ...")

# –°—á–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã
stop_count = 0
other_count = 0

for label, folder in [(1, "stop"), (0, "other")]:
    folder_path = os.path.join(DATA_DIR, folder)
    
    if not os.path.exists(folder_path):
        print(f"‚ùå –ü–∞–ø–∫–∞ {folder_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        continue
    
    files = [f for f in os.listdir(folder_path) if f.endswith(".wav")]
    print(f"   üìÅ {folder}: {len(files)} —Ñ–∞–π–ª–æ–≤")
    
    for file in files:
        path = os.path.join(folder_path, file)
        features = extract_mfcc(path)
        
        if features is not None:
            X.append(features)
            y.append(label)
            
            if label == 1:
                stop_count += 1
            else:
                other_count += 1

X = np.array(X)
y = np.array(y)

print(f"\n‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(X)} —Ñ–∞–π–ª–æ–≤:")
print(f"   üî¥ '–°–¢–û–ü': {stop_count} —Ñ–∞–π–ª–æ–≤")
print(f"   üîµ '–î—Ä—É–≥–∏—Ö': {other_count} —Ñ–∞–π–ª–æ–≤")
print(f"   üìä –í—Å–µ–≥–æ: {len(X)} –ø—Ä–∏–º–µ—Ä–æ–≤")

if len(X) < 100:
    print(f"\n‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö! –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 100, –∞ –µ—Å—Ç—å {len(X)}")
    print("   –î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –∑–∞–ø–∏—Å–µ–π —á–µ—Ä–µ–∑ record_better.py")
    exit()

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
print(f"   –û–±—É—á–µ–Ω–∏–µ: {len(X_train)} –ø—Ä–∏–º–µ—Ä–æ–≤")
print(f"   –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {len(X_test)} –ø—Ä–∏–º–µ—Ä–æ–≤")

# –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(MAX_LEN, 39)),
    
    # –ü–µ—Ä–≤—ã–π —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
    tf.keras.layers.Conv1D(32, 3, activation="relu", padding="same"),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(2),
    
    # –í—Ç–æ—Ä–æ–π —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
    tf.keras.layers.Conv1D(64, 3, activation="relu", padding="same"),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling1D(2),
    
    # –¢—Ä–µ—Ç–∏–π —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
    tf.keras.layers.Conv1D(128, 3, activation="relu", padding="same"),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.GlobalAveragePooling1D(),
    
    # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(32, activation="relu"),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation="sigmoid")
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss="binary_crossentropy",
    metrics=["accuracy", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]
)

print("\nüß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:")
model.summary()

print("\n‚è≥ –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ (—ç—Ç–æ –∑–∞–π–º—ë—Ç 3-5 –º–∏–Ω—É—Ç)...")

# –û–±—É—á–µ–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏—Å—Ç–æ—Ä–∏–∏
history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=30,
    batch_size=16,
    verbose=1
)

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É models –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
os.makedirs("models", exist_ok=True)
model.save("models/stop_model.h5")
print("\nüíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/stop_model.h5")

# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
print("\nüìä –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò –ù–ê –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–•:")
loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)

print(f"   –¢–æ—á–Ω–æ—Å—Ç—å (Accuracy): {accuracy:.1%}")
print(f"   Precision: {precision:.1%} (–º–∞–ª–æ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π)")
print(f"   Recall: {recall:.1%} (–º–∞–ª–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö '—Å—Ç–æ–ø')")

# F1-score
f1 = 2 * (precision * recall) / (precision + recall + 1e-6)
print(f"   F1-Score: {f1:.1%} (–±–∞–ª–∞–Ω—Å —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ –ø–æ–ª–Ω–æ—Ç—ã)")

# –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
print(f"\nüéØ –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø:")
if accuracy > 0.95:
    print("   ‚úÖ –û–¢–õ–ò–ß–ù–û! –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")
elif accuracy > 0.90:
    print("   üëç –•–û–†–û–®–û! –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.")
elif accuracy > 0.85:
    print("   ‚ö†Ô∏è –ù–û–†–ú–ê–õ–¨–ù–û! –ú–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –µ—â—ë –¥–∞–Ω–Ω—ã—Ö.")
else:
    print("   ‚ùå –ü–õ–û–•–û! –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")

# –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
try:
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='–û–±—É—á–µ–Ω–∏–µ')
    plt.plot(history.history['val_accuracy'], label='–í–∞–ª–∏–¥–∞—Ü–∏—è')
    plt.title('–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏')
    plt.xlabel('–≠–ø–æ—Ö–∏')
    plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
    plt.legend()
    plt.grid(True)
    
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='–û–±—É—á–µ–Ω–∏–µ')
    plt.plot(history.history['val_loss'], label='–í–∞–ª–∏–¥–∞—Ü–∏—è')
    plt.title('–ü–æ—Ç–µ—Ä–∏ –º–æ–¥–µ–ª–∏')
    plt.xlabel('–≠–ø–æ—Ö–∏')
    plt.ylabel('–ü–æ—Ç–µ—Ä–∏')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig('models/training_history.png', dpi=100)
    print(f"üíæ –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: models/training_history.png")
    
except:
    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ (–≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ—Ç matplotlib)")

print("\n" + "="*60)
print("   üöÄ –ú–û–î–ï–õ–¨ –û–ë–£–ß–ï–ù–ê!")
print("="*60)
print("–¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å–∫–∞–π—Ç–µ –±—Ä–∞—Å–ª–µ—Ç:")
print("   python app.py")
print("\n–î–ª—è —Ç–µ—Å—Ç–∞ –≥–æ–≤–æ—Ä–∏—Ç–µ '—Å—Ç–æ–ø' —Å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è 1-1.5 –º–µ—Ç—Ä–∞.")