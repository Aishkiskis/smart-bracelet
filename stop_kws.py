import numpy as np
import librosa
import tensorflow as tf
from tensorflow import keras
import time
import os


class StopKWS:
    def __init__(self, model_path="models/stop_model.h5"):
        print("üß† –ó–∞–≥—Ä—É–∂–∞—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å STOP...")
        
        if not os.path.exists(model_path):
            print(f"‚ùå –ú–æ–¥–µ–ª—å {model_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            print("   –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å: python train_stop.py")
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å {model_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        self.model = keras.models.load_model(model_path)
        self.last_trigger = 0
        self.cooldown = 1.2
        self.sample_rate = 16000
        print("‚úÖ STOP –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞")
    
    def extract_features(self, audio, sr=16000):
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ 39 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ:
        - 13 MFCC –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤
        - 13 –¥–µ–ª—å—Ç–∞-MFCC
        - 13 –¥–µ–ª—å—Ç–∞-–¥–µ–ª—å—Ç–∞-MFCC
        –ò—Ç–æ–≥–æ: 39 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –∫–∞–¥—Ä
        """
        if len(audio) == 0:
            return np.zeros((40, 39))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float32 –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        audio = audio.astype(np.float32)
        max_val = np.max(np.abs(audio))
        if max_val > 0:
            audio = audio / max_val
        
        # 1. MFCC –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã (13 —à—Ç—É–∫) - –¢–û–ß–ù–û –ö–ê–ö –í –û–ë–£–ß–ï–ù–ò–ò!
        mfcc = librosa.feature.mfcc(
            y=audio,
            sr=sr,
            n_mfcc=13,  # –ë–´–õ–û 40, –î–û–õ–ñ–ù–û –ë–´–¢–¨ 13!
            n_fft=512,
            hop_length=256,
            n_mels=40
        )
        
        # 2. –î–µ–ª—å—Ç–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã (–µ—â—ë 13)
        mfcc_delta = librosa.feature.delta(mfcc)
        
        # 3. –î–µ–ª—å—Ç–∞-–¥–µ–ª—å—Ç–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã (–µ—â—ë 13)
        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)
        
        # 4. –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: 13 + 13 + 13 = 39
        all_features = np.vstack([mfcc, mfcc_delta, mfcc_delta2])
        
        # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º: (–∫–∞–¥—Ä—ã, 39 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
        all_features = all_features.T
        
        # 5. –û–±—Ä–µ–∑–∞–µ–º/–¥–æ–ø–æ–ª–Ω—è–µ–º –¥–æ 40 –∫–∞–¥—Ä–æ–≤
        if all_features.shape[0] < 40:
            pad = np.zeros((40 - all_features.shape[0], 39))
            all_features = np.vstack([all_features, pad])
        else:
            all_features = all_features[:40]
        
        return all_features
    
    def detect(self, audio, sr=16000):
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞ '–°–¢–û–ü' —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–ª–æ–≤–æ '—Å—Ç–æ–ø'
        """
        # –ó–∞—â–∏—Ç–∞ –æ—Ç —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
        now = time.time()
        if now - self.last_trigger < self.cooldown:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –∑–≤—É–∫ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≥—Ä–æ–º–∫–∏–π
        rms = np.sqrt(np.mean(audio ** 2))
        if rms < 0.01:  # –£–≤–µ–ª–∏—á–∏–ª –ø–æ—Ä–æ–≥
            return False
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ 39 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏!)
        features = self.extract_features(audio, sr)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏: (1, 40, 39)
        features = np.expand_dims(features, axis=0)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        prob = self.model.predict(features, verbose=0)[0][0]
        
        # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        print(f"[KWS] –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å '–°–¢–û–ü': {prob:.3f} (RMS: {rms:.4f})")
        
        # –ü–æ—Ä–æ–≥ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è - –£–í–ï–õ–ò–ß–ò–õ!
        if prob > 0.95:  # –ë–´–õ–û 0.85, –°–¢–ê–õ–û 0.95
            print(" ‚úÖ –°–¢–û–ü –û–ë–ù–ê–†–£–ñ–ï–ù–û!")
            self.last_trigger = now
            return True
        else:
            return False